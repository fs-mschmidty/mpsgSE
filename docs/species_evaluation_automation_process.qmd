---
title: Species Evaluation Automation Process
date: 2024-12-05
format:
  html: default
  pdf: default
  docx: default
execute:
  echo: true
  message: false
  warning: false
  class-output: 'r'
---

# Introduction

This document details the process of automating parts of the Mountain State Planning Group's (MPSG), Species Evaluations for Species of Conservation Concern (SCC). The MPSG is tasked with helping National Forests with planning efforts.  Part of the Pre-assessment portion of Forest Planning is writing Species Evaluations for SCC. Species assessments are intended to inform selection of SCC by the Regional Forester by providing the best available scientific (BASI) information on if there is "substantial concern about the speciesâ€™ capability to persist over the long-term in the plan area" (36 CFR 219.9(c)).  This process is detailed in draft in the "Species of Conservation Concern Identification Process" (CITE MPSG) document. This document is not intended to outline the SCC process.  Rather it will focus on documenting the automation of the process outlined in the SCC process document. 

Automation is recommended for this process for two primary reasons: hundreds of Species Evaluations are required for any given planning unit, resulting in a substantial workload.  Automation of repeatable steps decreases the workload of MPSG staff, produces more consistent and repeatable documents, and can help define, programmatically or otherwise, best sources of BASI and processes for retrieving BASI. 

# The Process

# Species Evaluation Automation Process

Broadly there are three parts to automating: 
1. Develop eligible list of species for potential listing as SCC
2. Gather available relevant BASI for species on the eligible list.
3. Automate SCC species evaluation templates with as much data pre input as possible.

## Process Preface

### The Use of R Programming Language

The MPSG uses the R programming language (CITE R) for much of the work we do in automation and will be referencing R code and packages in this document because it helps explain how we accomplished a lot of what we did.  However, automation is not necessarily dependent on R.  Many of these processes could be completed by other means and R is irrelevant to many of the data sources and structures we have developed at the MPSG. 

### Taxonomy
Before we explain the steps in the automation process it is important to mention how we handled species taxonomy.  One of the first hurdles that needed to be overcome at the beginning of automating the species evaluation process was how we were going to resolve taxonomy in a systematic and programmatic way. This process relies on dozens of external resources for information.  Many of those resources have their own methods for dealing with taxonomy, but almost all of them differ in how they define species.  This is particularly problematic in the botany world where many experts and institutions differ on plant taxonomy.  When we retrieve a list of species, weather it be status, spatial or some other resource, we needed a way to algorithmically settle on what that species was. It is important that it could be done algorythmically because we had to parse hundreds of thousands of records during this process. 

We tried a variety of resources to resolve taxonomies, but ultimately landed on using the [`taxize`] R package to access the GBIF Backbone Taxonomy. 

## Build Eligible List

### Unit Spatial Layers and Other Unit Relevant Spatial Layers

Spatial administrative boundary data (S_USA.AdministrativeForest) are acquired from the Forest Service Enterprise Data Warehouse (EDW). 
Forest or grassland boundaries are subseted using a Definition Query for that Forest Service unit in ArcGIS Pro (ESRI Inc. 2024).
The administrative boundary is used to clip (Analysis Toolbox, ArcGIS Pro, ESRI Inc. 2024) Forest Service owned lands, or Plan Area, from the EDW basic ownership data (S_USA.BasicOwnership).
The administrative boundary and plan area data are exported to a geodatabse for use through out the plan revision process.
One-kilometer buffers are created around the administrative boundary and the plan area using the Buffer tool (Analysis Toolbox, ArcGIS Pro, ESRI Inc. 2024) to capture observations immediately adjacent to the plan area.

### Natureserve State List

1. Pull all species from natureserve for any given state[`mpsgSE::get_ns_state_list`](https://github.com/fs-mschmidty/mpsgSE/blob/main/R/get_ns_state_list.R)
  a. Scientific  Name
  b. Global Rank
  c. State Rank for given state. 
  d. USFWS status
2. Merge State Lists if necessary and keep only unique species
3. Use [`mpsgSE::get_taxonomies()`](https://github.com/fs-mschmidty/mpsgSE/blob/main/R/get_taxonomies.R) to acquire unique ID. 

### Get Occurrence Data

<!-- Matt I think it would be best if you wrote this section. -->
<!-- For now these lists are just the lists have occurrence numbers and not the actual spatial data! (see section below "Load Occurrence Spatial Data") -->

The following datasets are assigned a taxonomic ID using the [`mpsgSE::get_taxonomies()`](https://github.com/fs-mschmidty/mpsgSE/blob/main/R/get_taxonomies.R) function and summarized to the species, subspecies, or variety level.

#### Global Biodiversity Information Facility

Global Biodiversity Information Facility (GBIF; Global Biodiversity Information Facility 2022a) is a repository of externally sourced species occurrence records from museum collections, academic studies, and citizen science programs.
GBIF records requests are staged on GBIF servers and have to be downloaded (see [Getting Occurrence Data From GBIF](https://docs.ropensci.org/rgbif/articles/getting_occurrence_data.html) for details).
An R script submits a records request using the 1-km buffer around the administrative boundary to spatially query GBIF records. 
The data are downloaded in [Darwin Core Archive format](https://www.gbif.org/darwin-core) (GBIF, 2022b) for full data provenance.
The data are unzipped and read in to R once the request is available using the `rgbif` package (version 3.7.8, Chamberlain et al. 2023).

#### SEINet

[SEINet](https://swbiodiversity.org/seinet/index.php) is a data portal that provides a suite of data access tools, including species occurrence data from museums, collections, and state and federal agencies. 
SEINet data are available through an online data portal and are downloaded manually.
A polygon box, or well-known text (WKT) footprint, is drawn around the administrative boundary to query species observations using the Taxonomic Criteria search page (<https://swbiodiversity.org/seinet/collections/harvestparams.php>).
The query results are downloaded in Darwin Core Archive format, manually unzipped, and a script reads them into R.

#### EO State Data (NHP Data)

State Natural Heritage Programs (NHPs) provide species occurrence data, and habitat and distribution models for federal, state, and non-governmental agencies throughout their state. 
Element occurrence (EO) spatial data are requested from an HNP which are often provided in a geodatabase.
The EO data are read to R using an R script.

#### Integrated Monitoring in Bird Conservation Regions
The [Integrated Monitoring in Bird Conservation Regions (IMBCR)](https://www.birdconservancy.org/what-we-do/science/monitoring/imbcr-program/) is a long-term avian monitoring program coordinated by the [Birds Conservancy of the Rockies](https://www.birdconservancy.org/), and maintains monitoring plots on public lands throughout Forest Service Regions 1-4. 
IMBCR data spanning 2008-2023 were obtained for Forest Service lands on 12 December, 2023, for use in these analyses. 
These data were received in and Excel file and an script reads them into R.

* NABat Data

<!-- I'm not currently pulling NABat data because the process is prohibitive to do so across the MPSG footprint. -->

* Maybe why we don't us Idigbio anymore

The iDigBio Project (iDigBio 2023) is a repository of digitized vouchered natural history collections including the [Consortium of Lichen Herbaria](https://lichenportal.org/portal/), the [Consortium of Bryophyte Herbaria](https://bryophyteportal.org/portal/), and [Rocky Mountain Herbarium](https://rmh.uwyo.edu/data/search.php).
iDigBio records are available through an API and can be accessed using the `spocc` package (version `r packageVersion('spocc')`, Owens and Chamberlain 2023).
An R script submits a records request using the 1-km buffer around the administrative boundary to spatially query iDigBio records, which are read directly into R.

<!--
Do we want to a include data limitations section?
-->

###  Get Qualifying Lists

* State T and E, and Tier 1 Lists
* Regional Sensitive Species Lists
* Neighboring Unit SCC lists
* USFWS Status (see above in Natureserve)

### Make Preliminary Eligible List

* To the Natureserve State List, which already includes global, state and USFWS ranks, full_join (So that if  species is not on one list it does not get dropped) by taxon_id:
  * State SWAP Lists
  * State T and E list
  * Regional Foresters List
  * Neighboring SCC lists
* Then to create all potential species eligible filter the list by: 
  * G/T 1,2 or 3 Ranks.
  * Any S/T 1 or 2 Ranks.
  * State SWAP Tier 1 Ranks
  * State T and E Ranks
  * Regional Foresters Sensitive Species Lists
  * Neighboring Regional SCC Designation
* Join all occurrence lists to all potential species eligible filtered list
* Filter by those species that have one occurrence record in the planning unit.

#### Notes on Taxonomic Problems in the Process

### Manually Check Accidental Transients, Native and Known, and Local Concern, to Produce Final SCC Eligible List

<!-- I think we should add into this process the Units local concern species -->

#### Transient Bird List
* Get ebird maps from ebirdst
* Do check on each species
* Output for manual checking

#### Filter those species that need native and known checks
* Those  species with less than 6 occurrences combined from each list in the planning area.
* Those species with their most recent detection being greater than 40 years ago. 

#### Species with uncertain taxanomic determinations
* Multiple species may be taxonomically identified as the same species with `get_taxonomies()`.  Becuase we cannot determine their taxonomic status programatically, we cannot join them to occurrence lists or status lists. Therefore they must be manually vetted. 

#### Get user feedback
#### Use user feedback to refine list
Based on manual checks remove species that are:
* Determined to not be native and known. 
* Determined to be accidental or transients
* ! Determined to be of local concern by the unit

## Retrieve External Data for Automating Reports

### Get Synonyms

### Get Data for Making Automated Maps

#### Load Occurrence Spatial Data

GBIF data are acquired using the [`mpsgSE::get_gbif()`](https://github.com/fs-mschmidty/mpsgSE/blob/main/R/get_gibif.R) function. This function submits a record request, and downloads and read the data into R when the request if complete. 
The data are then summarized using the [`mpsgSE::gbif_spp()`](https://github.com/fs-mschmidty/mpsgSE/blob/main/R/gbif_spp.R) function and a list of species recorded in the plan area and 1-km buffer of the plan area is created using the [`mpsgSE::compile_gbif_list()`](https://github.com/fs-mschmidty/mpsgSE/blob/main/R/compile_gbif_list.R) function.
The resulting data are saved in an *.RData file, a data format specific to the R coding language, and loaded back into R when the automated reports are created.

Currently, SEINet, State NHP EO, and IMBCR data are read into R and summarized using individual R scripts that follow similar workflows as the GBIF data. 
These scripts will be converted to R functions and included in the `mpsgSE` package in the near future.

#### Load Species Distribution Models

* IUCN
* BIEN Plant Maps
* Ebird Maps

#### Get Other Base Map Information

* State Boundaries
* United States - lower 48
* North America
* The Americas (North and South America)
* Get Open Street Map Highways ("highway")
  * motorway
  * trunk
  * primary
* Clean Unit Names

#### Get Natureserve Habitats From the Natureserve API and Manually Crosswalk to Ecology

#### Retrieve, Clean, and Build Narratives for IMBCR Trend Information

#### Retrieve, Clean, and Build Narratives for Breeding Bird Survey

## Automate Reports
<!-- Look at the qmd and write out each section.  (Maybe should wait until we finish revamping the reports) -->

















